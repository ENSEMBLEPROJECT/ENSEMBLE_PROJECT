{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Mounting on drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdbwvvYlGqX9",
        "outputId": "9ae4b27c-d8ce-43b8-dd93-67b31db76257"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qx7LXuy9EFh-",
        "outputId": "7df2a4f8-1aed-4511-d7e0-897f8874b1f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train Summary:\n",
            "                  ID       DAY_ID COUNTRY  DE_CONSUMPTION  FR_CONSUMPTION  \\\n",
            "count   1494.000000  1494.000000    1494     1494.000000     1494.000000   \n",
            "unique          NaN          NaN       2             NaN             NaN   \n",
            "top             NaN          NaN      FR             NaN             NaN   \n",
            "freq            NaN          NaN     851             NaN             NaN   \n",
            "mean    1072.759036   591.861446     NaN        0.427442       -0.020032   \n",
            "std      618.013179   345.065043     NaN        0.673412        0.918995   \n",
            "min        0.000000     0.000000     NaN       -2.265563       -1.462350   \n",
            "25%      540.250000   292.250000     NaN       -0.037421       -0.716771   \n",
            "50%     1077.500000   591.000000     NaN        0.357061       -0.394166   \n",
            "75%     1597.500000   885.750000     NaN        0.922057        0.650533   \n",
            "max     2146.000000  1215.000000     NaN        2.033851        3.300640   \n",
            "\n",
            "        DE_FR_EXCHANGE  FR_DE_EXCHANGE  DE_NET_EXPORT  FR_NET_EXPORT  \\\n",
            "count      1494.000000     1494.000000    1494.000000    1494.000000   \n",
            "unique             NaN             NaN            NaN            NaN   \n",
            "top                NaN             NaN            NaN            NaN   \n",
            "freq               NaN             NaN            NaN            NaN   \n",
            "mean         -0.143073        0.143073      -0.235057      -0.069240   \n",
            "std           0.962250        0.962250       0.919546       1.050420   \n",
            "min          -2.856874       -2.634831      -2.464849      -2.825331   \n",
            "25%          -0.869990       -0.631683      -0.921263      -0.820640   \n",
            "50%          -0.119520        0.119520      -0.191500       0.041508   \n",
            "75%           0.631683        0.869990       0.395910       0.774676   \n",
            "max           2.634831        2.856874       2.279619       1.951516   \n",
            "\n",
            "        DE_NET_IMPORT  ...  FR_RESIDUAL_LOAD      DE_RAIN      FR_RAIN  \\\n",
            "count     1494.000000  ...       1494.000000  1494.000000  1494.000000   \n",
            "unique            NaN  ...               NaN          NaN          NaN   \n",
            "top               NaN  ...               NaN          NaN          NaN   \n",
            "freq              NaN  ...               NaN          NaN          NaN   \n",
            "mean         0.235057  ...         -0.153688    -0.035451     0.018139   \n",
            "std          0.919546  ...          0.896325     0.952789     1.018143   \n",
            "min         -2.279619  ...         -1.678936    -2.128531    -1.726420   \n",
            "25%         -0.395910  ...         -0.802333    -0.618791    -0.488625   \n",
            "50%          0.191500  ...         -0.460160    -0.211042    -0.193154   \n",
            "75%          0.921263  ...          0.382191     0.274779     0.125947   \n",
            "max          2.464849  ...          2.918326     7.756118     9.473201   \n",
            "\n",
            "            DE_WIND      FR_WIND      DE_TEMP      FR_TEMP      GAS_RET  \\\n",
            "count   1494.000000  1494.000000  1494.000000  1494.000000  1494.000000   \n",
            "unique          NaN          NaN          NaN          NaN          NaN   \n",
            "top             NaN          NaN          NaN          NaN          NaN   \n",
            "freq            NaN          NaN          NaN          NaN          NaN   \n",
            "mean       0.102592     0.115354     0.008857     0.007876     0.058126   \n",
            "std        1.022798     1.021388     0.941288     0.971259     1.097768   \n",
            "min       -1.880419    -1.895319    -4.549638    -5.787097    -5.349463   \n",
            "25%       -0.633867    -0.645796    -0.577139    -0.597690    -0.624238   \n",
            "50%       -0.193572    -0.146217     0.000000     0.000000     0.008493   \n",
            "75%        0.587377     0.677040     0.569285     0.650856     0.676415   \n",
            "max        5.085624     4.965028     2.858758     2.817239     5.674778   \n",
            "\n",
            "           COAL_RET   CARBON_RET  \n",
            "count   1494.000000  1494.000000  \n",
            "unique          NaN          NaN  \n",
            "top             NaN          NaN  \n",
            "freq            NaN          NaN  \n",
            "mean       0.061724     0.080510  \n",
            "std        1.033853     1.098624  \n",
            "min       -5.706442    -4.281790  \n",
            "25%       -0.458038    -0.522968  \n",
            "50%        0.063312     0.054056  \n",
            "75%        0.641446     0.599094  \n",
            "max        3.746576     5.471818  \n",
            "\n",
            "[11 rows x 35 columns]\n",
            "X_train Missing Values:\n",
            " ID                  3\n",
            "DAY_ID              3\n",
            "COUNTRY             7\n",
            "DE_CONSUMPTION      3\n",
            "FR_CONSUMPTION      3\n",
            "DE_FR_EXCHANGE      3\n",
            "FR_DE_EXCHANGE      3\n",
            "DE_NET_EXPORT       3\n",
            "FR_NET_EXPORT       3\n",
            "DE_NET_IMPORT       3\n",
            "FR_NET_IMPORT       3\n",
            "DE_GAS              3\n",
            "FR_GAS              3\n",
            "DE_COAL             3\n",
            "FR_COAL             3\n",
            "DE_HYDRO            3\n",
            "FR_HYDRO            3\n",
            "DE_NUCLEAR          3\n",
            "FR_NUCLEAR          3\n",
            "DE_SOLAR            3\n",
            "FR_SOLAR            3\n",
            "DE_WINDPOW          3\n",
            "FR_WINDPOW          3\n",
            "DE_LIGNITE          3\n",
            "DE_RESIDUAL_LOAD    3\n",
            "FR_RESIDUAL_LOAD    3\n",
            "DE_RAIN             3\n",
            "FR_RAIN             3\n",
            "DE_WIND             3\n",
            "FR_WIND             3\n",
            "DE_TEMP             3\n",
            "FR_TEMP             3\n",
            "GAS_RET             3\n",
            "COAL_RET            3\n",
            "CARBON_RET          3\n",
            "dtype: int64\n",
            "Y_train Summary:\n",
            "                 ID       TARGET\n",
            "count  1494.000000  1494.000000\n",
            "mean   1072.759036     0.089934\n",
            "std     618.013179     1.034582\n",
            "min       0.000000    -6.519268\n",
            "25%     540.250000    -0.219861\n",
            "50%    1077.500000     0.000000\n",
            "75%    1597.500000     0.269719\n",
            "max    2146.000000     7.786578\n",
            "Y_train Missing Values:\n",
            " ID        0\n",
            "TARGET    0\n",
            "dtype: int64\n",
            "X_test Summary:\n",
            "                  ID       DAY_ID COUNTRY  DE_CONSUMPTION  FR_CONSUMPTION  \\\n",
            "count    654.000000   654.000000     654      654.000000      654.000000   \n",
            "unique          NaN          NaN       2             NaN             NaN   \n",
            "top             NaN          NaN      FR             NaN             NaN   \n",
            "freq            NaN          NaN     365             NaN             NaN   \n",
            "mean    1075.192661   632.744648     NaN        0.435242        0.034431   \n",
            "std      625.699109   356.751037     NaN        0.802119        0.985306   \n",
            "min        1.000000     4.000000     NaN       -7.433311       -4.591011   \n",
            "25%      528.500000   334.000000     NaN        0.045064       -0.718746   \n",
            "50%     1060.500000   633.500000     NaN        0.365394       -0.363841   \n",
            "75%     1631.500000   952.000000     NaN        0.986764        0.815481   \n",
            "max     2147.000000  1214.000000     NaN        1.851717        2.817944   \n",
            "\n",
            "        DE_FR_EXCHANGE  FR_DE_EXCHANGE  DE_NET_EXPORT  FR_NET_EXPORT  \\\n",
            "count       654.000000      654.000000     654.000000     654.000000   \n",
            "unique             NaN             NaN            NaN            NaN   \n",
            "top                NaN             NaN            NaN            NaN   \n",
            "freq               NaN             NaN            NaN            NaN   \n",
            "mean         -0.044341        0.044341      -0.205171      -0.120159   \n",
            "std           0.893916        0.893916       0.910296       0.987545   \n",
            "min          -2.226614       -2.437265      -2.413888      -2.532384   \n",
            "25%          -0.725250       -0.614152      -0.907724      -0.837220   \n",
            "50%           0.000000        0.000000      -0.130555       0.000000   \n",
            "75%           0.614152        0.725250       0.511167       0.729950   \n",
            "max           2.437265        2.226614       2.104596       1.935559   \n",
            "\n",
            "        DE_NET_IMPORT  ...  FR_RESIDUAL_LOAD     DE_RAIN     FR_RAIN  \\\n",
            "count      654.000000  ...        654.000000  654.000000  654.000000   \n",
            "unique            NaN  ...               NaN         NaN         NaN   \n",
            "top               NaN  ...               NaN         NaN         NaN   \n",
            "freq              NaN  ...               NaN         NaN         NaN   \n",
            "mean         0.205171  ...         -0.074680    0.080957   -0.015402   \n",
            "std          0.910296  ...          0.953129    1.137301    0.966666   \n",
            "min         -2.104596  ...         -3.978024   -1.919936   -2.046479   \n",
            "25%         -0.511167  ...         -0.784779   -0.570942   -0.463261   \n",
            "50%          0.130555  ...         -0.412427   -0.221044   -0.246076   \n",
            "75%          0.907724  ...          0.674864    0.308900    0.057304   \n",
            "max          2.413888  ...          2.513394    5.623228   11.489768   \n",
            "\n",
            "           DE_WIND     FR_WIND     DE_TEMP     FR_TEMP     GAS_RET  \\\n",
            "count   654.000000  654.000000  654.000000  654.000000  654.000000   \n",
            "unique         NaN         NaN         NaN         NaN         NaN   \n",
            "top            NaN         NaN         NaN         NaN         NaN   \n",
            "freq           NaN         NaN         NaN         NaN         NaN   \n",
            "mean      0.084998    0.074227   -0.036506   -0.046977    0.064510   \n",
            "std       0.977141    0.945073    0.981755    0.995797    1.077996   \n",
            "min      -1.326968   -1.398663   -3.970399   -2.474841   -3.281054   \n",
            "25%      -0.617664   -0.617903   -0.757155   -0.767317   -0.491379   \n",
            "50%      -0.083302   -0.172435   -0.015568   -0.049664    0.081457   \n",
            "75%       0.551698    0.650034    0.585433    0.581847    0.673917   \n",
            "max       7.149098    3.534035    3.113181    2.764172    4.219191   \n",
            "\n",
            "          COAL_RET  CARBON_RET  \n",
            "count   654.000000  654.000000  \n",
            "unique         NaN         NaN  \n",
            "top            NaN         NaN  \n",
            "freq           NaN         NaN  \n",
            "mean      0.098593    0.046548  \n",
            "std       0.998351    1.079842  \n",
            "min      -4.226691   -3.967640  \n",
            "25%      -0.456403   -0.556830  \n",
            "50%       0.122134    0.000485  \n",
            "75%       0.722652    0.594557  \n",
            "max       3.868088    4.575306  \n",
            "\n",
            "[11 rows x 35 columns]\n",
            "X_test Missing Values:\n",
            " ID                  3\n",
            "DAY_ID              3\n",
            "COUNTRY             7\n",
            "DE_CONSUMPTION      3\n",
            "FR_CONSUMPTION      3\n",
            "DE_FR_EXCHANGE      3\n",
            "FR_DE_EXCHANGE      3\n",
            "DE_NET_EXPORT       3\n",
            "FR_NET_EXPORT       3\n",
            "DE_NET_IMPORT       3\n",
            "FR_NET_IMPORT       3\n",
            "DE_GAS              3\n",
            "FR_GAS              3\n",
            "DE_COAL             3\n",
            "FR_COAL             3\n",
            "DE_HYDRO            3\n",
            "FR_HYDRO            3\n",
            "DE_NUCLEAR          3\n",
            "FR_NUCLEAR          3\n",
            "DE_SOLAR            3\n",
            "FR_SOLAR            3\n",
            "DE_WINDPOW          3\n",
            "FR_WINDPOW          3\n",
            "DE_LIGNITE          3\n",
            "DE_RESIDUAL_LOAD    3\n",
            "FR_RESIDUAL_LOAD    3\n",
            "DE_RAIN             3\n",
            "FR_RAIN             3\n",
            "DE_WIND             3\n",
            "FR_WIND             3\n",
            "DE_TEMP             3\n",
            "FR_TEMP             3\n",
            "GAS_RET             3\n",
            "COAL_RET            3\n",
            "CARBON_RET          3\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def load_datasets(x_train_path, y_train_path, x_test_path):\n",
        "    # Loading datasets\n",
        "    x_train = pd.read_csv(x_train_path)\n",
        "    y_train = pd.read_csv(y_train_path)\n",
        "    x_test = pd.read_csv(x_test_path)\n",
        "\n",
        "    # Replace missing values with 0\n",
        "    x_train.replace(' ', 0, inplace=True)\n",
        "    y_train.replace(' ', 0, inplace=True)\n",
        "    x_test.replace(' ', 0, inplace=True)\n",
        "\n",
        "\n",
        "    # Filling missing values with 0\n",
        "    x_train.fillna(0, inplace=True)\n",
        "    y_train.fillna(0, inplace=True)\n",
        "    x_test.fillna(0, inplace=True)\n",
        "\n",
        "\n",
        "    # Describing the datasets to check for missing values\n",
        "    dataframes_info = {\n",
        "        'X_train': x_train.describe(include='all'),\n",
        "        'Y_train': y_train.describe(include='all'),\n",
        "        'X_test': x_test.describe(include='all')\n",
        "    }\n",
        "\n",
        "    # Output the descriptions\n",
        "    for name, df_info in dataframes_info.items():\n",
        "        print(f'{name} Summary:\\n', df_info)\n",
        "        print(f'{name} Missing Values:\\n', df_info.isnull().sum())\n",
        "    x_train.to_csv('filled_x_train.csv', index=False)\n",
        "    y_train.to_csv('filled_y_train.csv', index=False)\n",
        "    x_test.to_csv('filled_x_test.csv', index=False)\n",
        "    return x_train, y_train, x_test\n",
        "\n",
        "#Paths to the files\n",
        "x_train_path = \"/content/drive/MyDrive/ensemble/project/X_train_NHkHMNU.csv\"\n",
        "y_train_path = \"/content/drive/MyDrive/ensemble/project/y_train_ZAN5mwg.csv\"\n",
        "x_test_path = \"/content/drive/MyDrive/ensemble/project/X_test_final.csv\"\n",
        "\n",
        "\n",
        "#Loading datasets\n",
        "x_train, y_train, x_test = load_datasets(x_train_path, y_train_path, x_test_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Split dataset into train and validation sets\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "CKSiVo1BMn4n"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "class Boosting:\n",
        "    def __init__(self, base_models):\n",
        "        self.base_models = base_models\n",
        "        self.models = []\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        for base_model in self.base_models:\n",
        "            model = base_model\n",
        "            # Using only the second column of y\n",
        "            model.fit(X, y.iloc[:, 1])\n",
        "            self.models.append(model)\n",
        "\n",
        "    def predict(self, X):\n",
        "        predictions = np.zeros((len(X), len(self.models)))\n",
        "        for i, model in enumerate(self.models):\n",
        "            predictions[:, i] = model.predict(X)\n",
        "        # sum of predictions for regression\n",
        "        return np.sum(predictions, axis=1)\n"
      ],
      "metadata": {
        "id": "xsbuXptLHUA5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the original 'country' column from X_train and X_val\n",
        "X_train.drop(columns=['COUNTRY'], inplace=True)\n",
        "X_val.drop(columns=['COUNTRY'], inplace=True)"
      ],
      "metadata": {
        "id": "LRMgotxxTkaR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer"
      ],
      "metadata": {
        "id": "cf0GiZApjgOn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Applying grid search method to find best parameters"
      ],
      "metadata": {
        "id": "ZGEI8aPlvacG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# parameter grid for RandomForestRegressor\n",
        "param_grid_rf = {\n",
        "    'n_estimators': [50, 100],\n",
        "    'max_depth': [None, 10],\n",
        "    'min_samples_split': [ 5,10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "#  parameter grid for DecisionTreeRegressor\n",
        "param_grid_dt = {\n",
        "    'max_depth': [None, 10],\n",
        "    'min_samples_split': [ 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Performing GridSearch on RandomForestRegressor\n",
        "grid_search_rf = GridSearchCV(RandomForestRegressor(), param_grid_rf, cv=5, scoring='neg_mean_squared_error')\n",
        "grid_search_rf.fit(X_train, Y_train.iloc[:, 1])\n",
        "\n",
        "# Perform GridSearch on DecisionTreeRegressor\n",
        "grid_search_dt = GridSearchCV(DecisionTreeRegressor(), param_grid_dt, cv=5, scoring='neg_mean_squared_error')\n",
        "grid_search_dt.fit(X_train, Y_train.iloc[:, 1])\n",
        "\n",
        "# Best parameters and best score for RandomForestRegressor\n",
        "best_params_rf = grid_search_rf.best_params_\n",
        "best_score_rf = grid_search_rf.best_score_\n",
        "\n",
        "# Best parameters and best score for DecisionTreeRegressor\n",
        "best_params_dt = grid_search_dt.best_params_\n",
        "best_score_dt = grid_search_dt.best_score_\n",
        "\n",
        "print(\"Best parameters for RandomForestRegressor:\", best_params_rf)\n",
        "print(\"Best score for RandomForestRegressor:\", best_score_rf)\n",
        "print(\"Best parameters for DecisionTreeRegressor:\", best_params_dt)\n",
        "print(\"Best score for DecisionTreeRegressor:\", best_score_dt)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2H1c86nGlvcq",
        "outputId": "2a03fcca-d0d7-4b3a-89c8-8506a86681b4"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters for RandomForestRegressor: {'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 100}\n",
            "Best score for RandomForestRegressor: -1.0427244029427645\n",
            "Best parameters for DecisionTreeRegressor: {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 10}\n",
            "Best score for DecisionTreeRegressor: -1.234198844075998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#rf_max_depth = 10\n",
        "#dt_max_depth = 5\n",
        "rf_model = RandomForestRegressor(**best_params_rf)\n",
        "dt_model = DecisionTreeRegressor(**best_params_dt)\n",
        "\n",
        "\n",
        "#Combining best parameters\n",
        "base_models = [rf_model, dt_model]"
      ],
      "metadata": {
        "id": "HSSaKqj4mPZb"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "boosting = Boosting(base_models=base_models)\n",
        "\n",
        "# Train the ensemble model obtained using randomforest and decision tree\n",
        "boosting.fit(X_train, Y_train)\n",
        "y_pred_train = boosting.predict(X_train)\n",
        "\n",
        "# Make predictions on the validation set\n",
        "y_pred_val = boosting.predict(X_val)\n",
        "\n",
        "# Mean Absolute Error (MAE) on training data\n",
        "train_mae = mean_absolute_error(Y_train.iloc[:, 1], y_pred_train)\n",
        "\n",
        "print(\"Training Mean Absolute Error:\", train_mae)\n",
        "# Mean Squared Error (MSE)  on training data\n",
        "train_mse = mean_squared_error(Y_train.iloc[:, 1], y_pred_train)\n",
        "print(\"Training Mean Squared Error:\", train_mse)\n",
        "#Mean Absolute Error (MAE) on validation data\n",
        "val_mae = mean_absolute_error(Y_val.iloc[:, 1], y_pred_val)\n",
        "\n",
        "print(\"Validation Mean Absolute Error:\", val_mae)\n",
        "# Mean Squared Error (MSE) on validation data\n",
        "val_mse = mean_squared_error(Y_val.iloc[:, 1], y_pred_val)\n",
        "print(\"Validation Mean Squared Error:\", val_mse)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bi0BTbakI-A7",
        "outputId": "4af761d2-2f65-4a38-922b-28042f855745"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Mean Absolute Error: 0.44552083233946854\n",
            "Training Mean Squared Error: 0.5091368284902642\n",
            "Validation Mean Absolute Error: 0.8217926138335472\n",
            "Validation Mean Squared Error: 1.8255792342578128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finding cross validation scores"
      ],
      "metadata": {
        "id": "VGYjTRDUw0dL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.base import BaseEstimator, RegressorMixin\n",
        "from sklearn.model_selection import cross_val_score\n",
        "class BoostingWrapper(BaseEstimator, RegressorMixin):\n",
        "    def __init__(self, base_models):\n",
        "        self.base_models = base_models\n",
        "        self.models = []\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        for base_model in self.base_models:\n",
        "            model = base_model\n",
        "            model.fit(X, y)\n",
        "            self.models.append(model)\n",
        "\n",
        "    def predict(self, X):\n",
        "        predictions = np.zeros((len(X), len(self.models)))\n",
        "        for i, model in enumerate(self.models):\n",
        "            predictions[:, i] = model.predict(X)\n",
        "        return np.sum(predictions, axis=1)\n",
        "\n",
        "X_full_train = pd.concat([X_train, X_val])\n",
        "Y_full_train = pd.concat([Y_train, Y_val])\n",
        "\n",
        "# Using BoostingWrapper for cross-validation\n",
        "boosting_wrapper = BoostingWrapper(base_models)\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_scores = cross_val_score(boosting_wrapper, X_full_train, Y_full_train.iloc[:, 1], cv=5, scoring='neg_mean_absolute_error')\n",
        "\n",
        "# Convert scores to positive since cross_val_score returns negative values for MAE\n",
        "cv_scores = -cv_scores\n",
        "\n",
        "# Print the cross-validation scores\n",
        "print(\"Cross-Validation Scores:\", cv_scores)\n",
        "\n",
        "# Calculate the mean cross-validation score\n",
        "mean_cv_score = cv_scores.mean()\n",
        "print(\"Mean Cross-Validation Score:\", mean_cv_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8cIxCE-id5b",
        "outputId": "523e1b30-493c-4172-87fc-c647af1a4dd7"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation Scores: [0.79396484 0.74909851 0.80145244 0.76595311 0.81393416]\n",
            "Mean Cross-Validation Score: 0.7848806117580791\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Define the number of folds\n",
        "n_folds = 5\n",
        "\n",
        "# Initialize KFold object\n",
        "kf = KFold(n_splits=n_folds)\n",
        "\n",
        "# Initialize an empty list to store cross-validation scores\n",
        "cv_scores_val = []\n",
        "\n",
        "# Loop over the folds\n",
        "for train_index, val_index in kf.split(X_val):\n",
        "    # No need to split the validation data further, use X_val and Y_val directly\n",
        "    X_val_fold, Y_val_fold = X_val.iloc[val_index], Y_val.iloc[val_index]\n",
        "\n",
        "    # Train the model on the training data\n",
        "    boosting.fit(X_train, Y_train)\n",
        "\n",
        "    # Make predictions on the validation fold\n",
        "    y_pred_val_fold = boosting.predict(X_val_fold)\n",
        "\n",
        "    # Calculate mean absolute error on the validation fold\n",
        "    val_mae_fold = mean_absolute_error(Y_val_fold.iloc[:, 1], y_pred_val_fold)\n",
        "\n",
        "    # Append the validation fold score to the list of cross-validation scores\n",
        "    cv_scores_val.append(val_mae_fold)\n",
        "\n",
        "# Convert scores to positive since cross_val_score returns negative values for MAE\n",
        "cv_scores_val = np.array(cv_scores_val)\n",
        "\n",
        "# Print the cross-validation scores on validation data\n",
        "print(\"Cross-Validation Scores on Validation Data:\", cv_scores_val)\n",
        "\n",
        "# Calculate the mean cross-validation score on validation data\n",
        "mean_cv_score_val = cv_scores_val.mean()\n",
        "print(\"Mean Cross-Validation Score on Validation Data:\", mean_cv_score_val)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRVJmw_l8Uvf",
        "outputId": "3386c1d1-d134-40a8-ab3b-be9ba1b9febc"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation Scores on Validation Data: [1.38124976 1.64341639 2.22874624 2.66154269 3.21543169]\n",
            "Mean Cross-Validation Score on Validation Data: 2.2260773548611015\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import spearmanr\n",
        "\n",
        "# Compute Spearman's correlation coefficient for training data\n",
        "#spearman_corr_train, _ = spearmanr(Y_train.iloc[:, 1], y_pred_train)\n",
        "\n",
        "\n",
        "spearman_coefficient, _ = spearmanr(Y_full_train.iloc[:, 1], boosting_wrapper.predict(X_full_train))\n",
        "print(\"Spearman's correlation coefficient for training data:\", spearman_coefficient)\n",
        "# Compute Spearman's correlation coefficient for validation data\n",
        "spearman_corr_val, _ = spearmanr(Y_val.iloc[:, 1], y_pred_val)\n",
        "print(\"Spearman's correlation coefficient for validation data:\", spearman_corr_val)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5D2nmLYdDrr",
        "outputId": "8f623cae-f339-4829-dc63-f2da59ab1116"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spearman's correlation coefficient for training data: 0.7449966118576165\n",
            "Spearman's correlation coefficient for validation data: 0.2150214361069336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predicting on test data"
      ],
      "metadata": {
        "id": "7l1YYrQ5xI9u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "x_test.drop(columns=['COUNTRY'], inplace=True)\n",
        "# Predictions on the test data\n",
        "y_pred_test = boosting.predict(x_test)\n",
        "\n",
        "# Saving predictions to a CSV file\n",
        "pd.DataFrame(y_pred_test, columns=['predicted_price_variation']).to_csv(\"predicted_price_variation.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "akJeNpf5bw5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_pgPY-dB9cET"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}